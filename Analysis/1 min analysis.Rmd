---
title: "Analysis Part 2"
author: "Sean Merritt"
date: "3/16/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set
pacman::p_load(tidyverse, readxl, moments, SuperLearner, synthpop, caret, RColorBrewer )
```

We define a breakout song as those that had more than 700,000 listens on Pandora. We removed observations where the participant had heard the song previously and then aggregated the Immersion, Frustration, and Peak accross particiants to give the songs scores (N = 24). 

```{r include=FALSE}

Song_Study <- read_excel("Song Study.xlsx", 
                         sheet = "1st min") %>% 
    mutate(Breakout = ifelse(Song %in% c("Tonnes and I, Dance Monkey",
                                             "Gabby Barrett, The Good Ones",
                                             "Doja Cat, Like That",
                                             "Arizona Zervas, Roxanne",
                                             "Fire From the Gods, Right Now",
                                             "Yemi Alade, Shake",
                                             "Mahalia, What You Did",
                                             "Lil That, F.N",
                                             "Ali Gatie, It's You",
                                             "Tyla Yaweh, I Think I love Her",
                                             "Layton Green, Lil Baby, and City Girls, Leave Em Alone",
                                             "Isabella Merced, Papi",
                                             "Koffee, Rapture"
                                             
                                             ), 1, 0
                           )
         )


Song_Study %>% 
  jmv::ttestIS(vars = Immersion, group = Breakout, effectSize = T)
```

```{r}
Song_Study %>% 
  jmv::logRegBin(dep = Breakout,
                 covs = vars(Peak,Immersion, Frustration),
                 blocks = list(
                   list( 'Immersion'),
                   list("Frustration")),
                 refLevels = list(list(var = "Breakout", ref = "0" )), 
                 acc = T,
                 class = T,
                 modelTest = T, 
                 OR =T, 
                 collin = T) 
```

To improve our predictive accuracy, we trained a bagged machine learning model. We started by created a synthetic data set using the `synthpop` package in R with a final sample of 10,000. Synthetic sampling uses the relationship between variables to recreate data that is similar to the observed set (**Reference here**). We used the following variables to create the data set: breakout, immersion, peak, frustation, and invangelist.   

```{r}
dat_show_syn <- syn(Song_Study[c(3,4, 5, 17)], m =1, seed = 1, k = 10000, minnumlevels = 2)
dat_show_s <- dat_show_syn$syn
dat_show_s %>% 
  jmv::logRegBin(dep = Breakout,
                 covs = vars(Immersion, Frustration),
                 blocks = list(
                   list( 'Immersion'),
                   list("Frustration")),
                 refLevels = list(list(var = "Breakout", ref = "0" )), 
                 acc = T,
                 class = T,
                 modelTest = T, 
                 OR =T, 
                 collin = T)
```


```{r}  
set.seed(2)
train <- sample(1:nrow(dat_show_s), nrow(dat_show_s)*.5)
Train_show <- dat_show_s[train,]
test_show <- dat_show_s[-train ,]


y_show <- as.numeric(as.factor(Train_show$Breakout))-1
y.test_show <- as.matrix(as.numeric(as.factor(test_show$Breakout))-1)
x_show <- as.data.frame(Train_show[,c(1,2)])
x.test_show <- as.data.frame(test_show[,c(1,2)])
```

`SuperLearner` uses risk to tell the level of accuracy of a model and its corresponding coefficient to tell how much it contributed to the models predictions. We find that the k-nearest neighbor contributed to most of the models predictions (coef = .98, risk = .018) and the logistic regression contributed a little bit (coef = .013, risk = .20). While the neural net contributed nothing (coef = 0.00, risk = .19)

```{r}
model <- SuperLearner(y_show,
                      x_show,
                      family=binomial(),
                      SL.library=list("SL.glm", "SL.knn", "SL.nnet", "SL.ksvm"))

model
```

The bagged model performed on the test set and was able to accurately classify 97.20% of the time (*p* < .001). Breakouts and non-breakouts were classified correctly 97% of the time.  

```{r}
predictions_show <- predict.SuperLearner(model, newdata = x.test_show, X = x_show, Y = y_show)

conv.preds_show <- (ifelse(predictions_show$pred>=0.5,1,0))

# Create the confusion matrix
cm <- confusionMatrix(as.factor(conv.preds_show), as.factor(y.test_show))
cm

```

We then tested the model on the original data set. With a total accuracy of 95% (*p* < .001), we were able to correctly classifed every breakout song and misclassified only one non-breakout song. 

```{r}
x_final <- as.data.frame(Song_Study[,c(3,4)])
y_final <- as.matrix(as.numeric(as.factor(Song_Study$Breakout))-1)

predictions_show <- predict.SuperLearner(model, newdata = x_final, X = x_show, Y = y_show, onlySL = F)

conv.preds_show <- (ifelse(predictions_show$pred>=0.5,1,0))

# Create the confusion matrix
cm <- confusionMatrix(as.factor(conv.preds_show), as.factor(y_final))
cm
```

```{r}
set.seed(1)
iterations = 1000

variables = 4
output <- matrix(ncol=variables, nrow=iterations)

for(i in 1:iterations){
  data <- dat_show_s %>% 
    select(Breakout, Frustration, Immersion) %>% 
    sample_n( size = 5000, replace = T)
  x_final <- as.data.frame(data[,c(2,3)])
  y_final <- as.matrix(as.numeric(as.factor(data$Breakout))-1)

  predictions_show <- predict.SuperLearner(model, 
                                           newdata = x_final, 
                                           X = x_show, 
                                           Y = y_show, 
                                           onlySL = F)

  conv.preds_show <- (ifelse(predictions_show$pred>=0.5,1,0))

  # Create the confusion matrix
  cm <- confusionMatrix(as.factor(conv.preds_show),
                        as.factor(y_final))
  output[i,1] <- cm$table[1]
  output[i,2] <- cm$table[2]
  output[i,3] <- cm$table[3]
  output[i,4] <- cm$table[4]
} 

output <- data.frame(output)
output <- output %>% 
  mutate(neg = X1/(X1 + X2),
         pos = X4/(X4 + X3),
         model = "Bagged ML") %>% 
  select(neg,pos,model)


```

```{r}
set.seed(1)
iterations = 1000

variables = 4
output2 <- matrix(ncol=variables, nrow=iterations)

model <- glm(Breakout == 0 ~ Frustration + Immersion, dat_show_s , family = binomial)

for(i in 1:iterations){
  data <- dat_show_s %>% 
    select(Breakout, Immersion, Frustration) %>% 
    sample_n( size = 5000, replace = T)
  x_final <- as.data.frame(data[,c(2,3)])
  y_final <- as.matrix(as.numeric(as.factor(data$Breakout))-1)
  

  probabilities <- model %>% predict(x_final, type = "response")
  predicted.classes <- ifelse(probabilities > 0.5, "0", "1")

  cm <- confusionMatrix(as.factor(predicted.classes),
                        as.factor(y_final))
  output2[i,1] <- cm$table[1]
  output2[i,2] <- cm$table[2]
  output2[i,3] <- cm$table[3]
  output2[i,4] <- cm$table[4]
} 

output2 <- data.frame(output2)
output2 <- output2 %>% 
  mutate(neg = X1/(X1 + X2),
         pos = X4/(X4 + X3),
         model = "Logistic") %>% 
  select(neg,pos,model)

model_comparison <- output %>% 
  rbind(output2)

model_comparison %>% 
  group_by(model) %>% 
  summarize(pos_mean = mean(pos), pos_sd = sd(pos), neg_mean = mean(neg), neg_sd= sd(neg)) %>% 
  mutate(pos_top = pos_mean + pos_sd, 
         pos_bottom = pos_mean - pos_sd,
         neg_top = neg_mean + neg_sd,
         neg_bottom = neg_mean - neg_sd)

```
```{r}
model_comparison %>% 
  jmv::ttestIS(vars = pos, group = model, effectSize = T)

model_comparison %>% 
  jmv::ttestIS(vars = neg, group = model, effectSize = T)
```

```{r}
model_comparison %>%
  rename(Flop = "neg",
         Hit = "pos") %>% 
  pivot_longer(Flop:Hit, names_to = "Breakout", values_to = "Accuracy") %>% 
  group_by(model, Breakout) %>% 
  mutate(Average = mean(Accuracy), SE =  sd(Accuracy)) %>% 
  ggplot(aes(x = model, fill = Breakout, y = Average))+
  geom_bar(stat = "identity", position = "dodge")+
  geom_text(aes(label = round(Average, 2), y = Average + SE), position = position_dodge(0.8), vjust = -1) +
  geom_errorbar(aes(ymin = (Average -SE*2), ymax = (Average + SE*2)), width=0.4, colour="black", width =.4,alpha=0.9, size=.9, position = position_dodge(0.8))+
  scale_y_continuous(breaks = seq(0,1.1,by =.2))+
ylim(0,1.1)+
  scale_fill_brewer(palette = "Dark2")+
  theme_classic()+
  theme(legend.position = "bottom")+
  labs(fill = "", x= "", y = "Accuracy")

ggsave("model_comparions2.jpeg", width = 5, height = 5)
```

